<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <title>ErZabeh - Publications</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- css -->
    <link href="css/bootstrap.min.css" rel="stylesheet" />
    <link href="css/fancybox/jquery.fancybox.css" rel="stylesheet">
    <link href="css/jcarousel.css" rel="stylesheet" />
    <link href="css/flexslider.css" rel="stylesheet" />
    <link href="css/style.css" rel="stylesheet" />


    <!-- Theme skin -->
    <link href="skins/default.css" rel="stylesheet" />

</head>

<body>
    <div id="wrapper">
        <!-- start header -->
        <header>
            <div class="navbar navbar-default navbar-static-top">
                <div class="container">
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <a class="navbar-brand" href="index.html"><span>Er</span>fun <br><span> Z</span>abeh</a>
                    </div>
                    <div class="navbar-collapse collapse ">
                        <ul class="nav navbar-nav">
                            <li class="active"><a href="index.html">Home</a></li>
                            <li><a href="AboutMe.html">About Me</a></li>
                            <li><a href="Publication.html">Publication</a></li>
							<li class="active"><a href="Sotries.html">My Philosophy of Science</a></li>
                            <li><a href="CV.html">CV</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </header>
        <!-- end header -->
		
				<!-- Blog Post Section -->
		<section id="blog-post">
			<div class="container">
				---
				layout: post
				title: "Low-rank RNNs in ten minutes"
				excerpt: This post is an attempt at summarizing results obtained over five years of research in the laboratory of Srdjan Ostojic, at ENS Paris, on the uses of low-rank RNNs, in a ten-minutes read. Let's see if that's enough to catch your interest!
				use_math: true
				---

				<p>This post is an attempt at summarizing results obtained over five years of research in the laboratory of Srdjan Ostojic, at ENS Paris, on the uses of low-rank RNNs, in a ten-minutes read. Let's see if that's enough to catch your interest!</p>

				<p><em>This post has been written with invaluable inputs from several lab members, in particular Friedrich Schuessler, Francesca Mastrogiuseppe and Srdjan Ostojic. Many thanks to them!</em></p>

				<h2>Why low-rank RNNs?</h2>

				<p>Artificial neural networks are super cool. They are known for all sorts of computational prowesses, and they also happen to model brain processes quite well. Among artificial neural networks, there are recurrent neural networks (RNNs), which contain a pool of interconnected neurons, whose activity evolves over time. These networks can be trained to perform all sorts of cognitive tasks, and they exhibit activity patterns that are quite similar to what is observed in many brain areas!</p>

				<div class="centrer">
				<img src="{{site.url}}/assets/lowranksummary/rnn.jpg" width="300"/>
				<br/>
				A recurrent neural network is a population of recurrently connected neurons, receiving external inputs and outputting a certain readout (from Beiran et al. 2021b).
				</div>
				<br/>

				<p>A common approach nowadays to understand neural computations is the <em>state-space approach</em>: one looks at the collective activity of many neurons in a network as a <em>vector</em> $(x_1(t), \dots, x_N(t))$ in a high-dimensional state-space. It turns out the neural trajectories in this state-space are not random, but stay confined to some particular low-dimensional subspaces, or manifolds. If you are not familiar with these concepts, a lot of places on the internet summarize them very well<sup>[1]</sup>. However, a big remaining mystery is how connections in a network of neurons are able to generate this very organized collective activity, able to solve complex tasks. Indeed, computer scientists have figured out how to train neural connections to get a network to do a certain task, but this doesn't provide a deep understanding of why the obtained connections implement the task, leading some people to coin RNNs as "black-box models".</p>

				<div class="centrer">
				<img src="{{site.url}}/assets/lowranksummary/statespace.jpg" width="500"/>
				<br/>
				Neural state-space: each axis represents one neuron's activity or firing rate (it has much more than 3 dimensions of course). Illustration inspired on (Gallego, J. A., Perich, M. G., Miller, L. E., & Solla, S. A. (2017). Neural manifolds for the control of movement. Neuron, 94(5), 978-984.).
				</div>
				<br/>

				<p>A first paper, published by Francesca Matrogiuseppe and Srdjan Ostojic in 2018<sup>[2]</sup>, has shown that low-rank RNNs could be a solution to the mystery. A low-rank RNN is a network whose connections obey particular algebraic properties, namely the connectivity matrix is low-rank, and can be written formally as follows:</p>

				<div>
				$$
				\boldsymbol{J} = \boldsymbol{m}^{(1)}{\boldsymbol{n}^{(1)}}^T + \dots + \boldsymbol{m}^{(R)}{\boldsymbol{n}^{(R)}}^T
				$$
				</div>

				<p>where $\boldsymbol{m}^{(1)}, \dots, \boldsymbol{m}^{(R)}$ and $\boldsymbol{n}^{(1)}, \dots, \boldsymbol{n}^{(R)}$, all $N$-dimensional, and $R$ is the *rank* of the matrix $\boldsymbol{J}$. Such a decomposition may look cumbersome, but it actually has a lot of advantages. Indeed, although they were not a general subject of study before, low-rank matrices had made many appearances in the history of computational neuroscience and machine learning, and that is no coincidence<sup>[2b]</sup>.</p>

				<div class="centrer">
				<img src="{{site.url}}/assets/lowranksummary/lorank.jpg" width="500"/>
				<br/>
				A low-rank matrix can be written as a sum of outer products of vectors. From (Beiran et al., 2021b)
				</div>
				<br/>

				<p>In their paper, Francesca and Srdjan show that low-rank RNNs have provably low-dimensional patterns of activity, and that they can be designed to accomplish many interesting tasks like Go-NoGo or stimulus detection. An extensive mean-field theory showed that the statistics of connectivity could be linked to the dynamics of the network, paving the way for a deeper understanding of neural computations. Many papers followed, deepening different aspects of that theory, and it is now a good time to wrap up what we know about them, and what they can bring to neuroscience. I will cover some interesting tidbits about low-rank RNNs in a first part, and then give a quick overview of what the different papers are about.</p>

				<h2>Some properties of low-rank RNNs</h2>

				<ul>
				<li><strong>Low-dimensional dynamics</strong></li>
				<p>Low-rank RNNs are defined in terms of vectors. There are the recurrent connectivity vectors, namely the $\boldsymbol{m}^{(r)}$ and the $\boldsymbol{n}^{(r)}$ we mentioned before, and also some input vectors $\boldsymbol{I}^{(s)}$ feeding external signals to the RNN. An essential property, easy to prove mathematically, is that the neural activity vector $\boldsymbol{x}(t)$ in a low-rank RNN is constrained to lie in subspace spanned by the $\boldsymbol{m}^{(r)}$ vectors and by the $\boldsymbol{I}^{(s)}$ vectors. We can decompose this space into a *recurrently-driven subspace* and an *input-driven subspace*, which together explain all of the activity in an RNN.</p>
				<div class="centrer">
					<img src="{{site.url}}/assets/lowrank

				
			</div>
		</section>
		<!-- End Blog Post Section -->

		<!-- Erfun ending section -->
		<section id="footer">
			<div class="container">
				<div class="row">
					<div class="col-lg-12">
						<!-- Add any additional content for the footer section here -->
					</div>
				</div>
			</div>
		</section>
		<!-- End Erfun ending section -->
		
		<!-- jQuery -->
		<script src="https://code.jquery.com/jquery-3.6.4.min.js"></script>
		<!-- Include any additional scripts or plugins here -->
		<!-- Bootstrap JS -->
		<script src="js/bootstrap.min.js"></script>
		<!-- Fancybox -->
		<script src="js/fancybox/jquery.fancybox.pack.js"></script>
		<!-- Jcarousel -->
		<script src="js/jcarousel/jquery.jcarousel.min.js"></script>
		<!-- Flexslider -->
		<script src="js/flexslider/jquery.flexslider-min.js"></script>
		<!-- Custom scripts -->
		<script src="js/scripts.js"></script>
		
		</body>
		
		</html>



		
